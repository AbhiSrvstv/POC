{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhiSrvstv/POC/blob/main/loan_predcition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without agent langgraph"
      ],
      "metadata": {
        "id": "L5ZHZ-hgwJcR"
      },
      "id": "L5ZHZ-hgwJcR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aefb1bea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aefb1bea",
        "outputId": "1d3ca033-9967-4ba2-d30b-c931141a80a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf1f677",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "eaf1f677",
        "outputId": "624742c6-a92e-4e74-aa57-6b02ba328c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9a5c666b605927a5de.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9a5c666b605927a5de.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from google.colab import userdata # Import userdata to access Colab secrets\n",
        "\n",
        "# Function to call the Gemini API for loan risk prediction\n",
        "def predict_loan_risk(\n",
        "    applicant_age: int,\n",
        "    applicant_income: float,\n",
        "    loan_amount: float,\n",
        "    loan_term: int,\n",
        "    credit_score: int,\n",
        "    employment_length: int,\n",
        "    home_ownership: str,\n",
        "    loan_purpose: str,\n",
        "    existing_monthly_debts: float,\n",
        "    risk_agent_type: str # New parameter for multi-agent functionality\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Predicts loan risk using the Gemini API based on provided loan application details.\n",
        "\n",
        "    Args:\n",
        "        applicant_age (int): Age of the applicant in years.\n",
        "        applicant_income (float): Annual income of the applicant.\n",
        "        loan_amount (float): Requested loan amount.\n",
        "        loan_term (int): Loan term in months.\n",
        "        credit_score (int): Credit score of the applicant (e.g., FICO).\n",
        "        employment_length (int): Employment length in years.\n",
        "        home_ownership (str): Type of home ownership (Rent, Own, Mortgage, Other).\n",
        "        loan_purpose (str): Purpose of the loan (Debt Consolidation, Education, Home Improvement, Venture, Other).\n",
        "        existing_monthly_debts (float): Total existing monthly debt payments.\n",
        "        risk_agent_type (str): The type of risk assessment agent to use (e.g., 'General', 'Financial Stability', 'Credit History').\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string containing the predicted loan risk and justification.\n",
        "    \"\"\"\n",
        "    # Retrieve the API key from Colab secrets using userdata\n",
        "    # Your secret name is 'GOOGLE_API_KEY'\n",
        "    api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "    if not api_key:\n",
        "        return \"Error: Gemini API key not found. Please ensure your secret 'GOOGLE_API_KEY' is set up in Colab secrets and notebook access is enabled.\"\n",
        "\n",
        "    # Base prompt for the Gemini model\n",
        "    base_prompt = f\"\"\"\n",
        "    Analyze the following loan application details and predict the loan risk as \"Low Risk\", \"Medium Risk\", or \"High Risk\".\n",
        "    Provide a detailed justification for your prediction, explaining the key factors that led to the assessment.\n",
        "\n",
        "    Loan Application Details:\n",
        "    - Applicant Age: {applicant_age} years\n",
        "    - Applicant Income: ${applicant_income} per year\n",
        "    - Loan Amount: ${loan_amount}\n",
        "    - Loan Term: {loan_term} months\n",
        "    - Credit Score: {credit_score} (out of 850)\n",
        "    - Employment Length: {employment_length} years\n",
        "    - Home Ownership: {home_ownership}\n",
        "    - Loan Purpose: {loan_purpose}\n",
        "    - Existing Monthly Debts: ${existing_monthly_debts}\n",
        "    \"\"\"\n",
        "\n",
        "    # Customize prompt based on agent type\n",
        "    if risk_agent_type == \"Financial Stability Agent\":\n",
        "        agent_specific_instruction = \"Focus your justification primarily on the applicant's income, existing debts, and the loan amount relative to their financial capacity.\"\n",
        "    elif risk_agent_type == \"Credit History Agent\":\n",
        "        agent_specific_instruction = \"Focus your justification primarily on the applicant's credit score and employment stability.\"\n",
        "    else: # Default to General Risk Agent\n",
        "        agent_specific_instruction = \"Provide a comprehensive justification considering all relevant factors.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    {base_prompt}\n",
        "    {agent_specific_instruction}\n",
        "\n",
        "    Please format your response strictly as follows:\n",
        "    Risk: [Your Prediction]\n",
        "    Justification: [Your Detailed Justification]\n",
        "    \"\"\"\n",
        "\n",
        "    chat_history = [{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}]\n",
        "\n",
        "    payload = {\n",
        "        \"contents\": chat_history,\n",
        "        \"generationConfig\": {\n",
        "            \"responseMimeType\": \"text/plain\",\n",
        "            \"temperature\": 0.7, # Added temperature to encourage more varied responses\n",
        "        },\n",
        "    }\n",
        "\n",
        "    api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key={api_key}\"\n",
        "\n",
        "    retries = 0\n",
        "    max_retries = 5\n",
        "    base_delay = 1  # 1 second\n",
        "\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                api_url,\n",
        "                headers={'Content-Type': 'application/json'},\n",
        "                data=json.dumps(payload)\n",
        "            )\n",
        "            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "\n",
        "            result = response.json()\n",
        "\n",
        "            # Check for content filtering or empty candidates\n",
        "            if result.get(\"candidates\") and len(result[\"candidates\"]) > 0:\n",
        "                if result[\"candidates\"][0].get(\"finishReason\") == \"SAFETY\":\n",
        "                    return \"Prediction blocked due to safety concerns. Please adjust input or prompt.\"\n",
        "                if result[\"candidates\"][0].get(\"content\") and \\\n",
        "                   result[\"candidates\"][0][\"content\"].get(\"parts\") and \\\n",
        "                   len(result[\"candidates\"][0][\"content\"][\"parts\"]) > 0:\n",
        "                    text = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "\n",
        "                    # Robust parsing for Risk and Justification\n",
        "                    prediction_text = \"N/A\"\n",
        "                    justification_text = \"The model did not provide a specific justification for this prediction.\"\n",
        "\n",
        "                    # Find the start of \"Risk:\" and \"Justification:\"\n",
        "                    risk_start_idx = text.find(\"Risk:\")\n",
        "                    justification_start_idx = text.find(\"Justification:\")\n",
        "\n",
        "                    if risk_start_idx != -1:\n",
        "                        # Extract prediction text between \"Risk:\" and \"Justification:\" or end of string\n",
        "                        if justification_start_idx != -1 and justification_start_idx > risk_start_idx:\n",
        "                            prediction_text = text[risk_start_idx + len(\"Risk:\"):justification_start_idx].strip()\n",
        "                        else:\n",
        "                            prediction_text = text[risk_start_idx + len(\"Risk:\"):].strip()\n",
        "                        # Clean up prediction_text if it contains \"Justification:\"\n",
        "                        if \"Justification:\" in prediction_text:\n",
        "                            prediction_text = prediction_text.split(\"Justification:\")[0].strip()\n",
        "\n",
        "\n",
        "                    if justification_start_idx != -1:\n",
        "                        # Extract everything after \"Justification:\"\n",
        "                        justification_text = text[justification_start_idx + len(\"Justification:\"):].strip()\n",
        "                        if not justification_text: # If it's still empty, use default\n",
        "                            justification_text = \"The model did not provide a specific justification for this prediction.\"\n",
        "\n",
        "\n",
        "                    return (\n",
        "                        f\"**Predicted Risk ({risk_agent_type}):** {prediction_text}\\n\\n\"\n",
        "                        f\"**Justification:** {justification_text}\"\n",
        "                    )\n",
        "                else:\n",
        "                    return \"Error: Gemini API returned an empty content part. This might indicate an issue with the model's generation.\"\n",
        "            else:\n",
        "                return \"Error: Gemini API returned no candidates for prediction. This could be due to content filtering or an internal model error.\"\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            status_code = e.response.status_code\n",
        "            error_detail = e.response.text\n",
        "            if status_code == 400:\n",
        "                return f\"API Error (400 Bad Request): Invalid input or request format. Details: {error_detail}\"\n",
        "            elif status_code == 403:\n",
        "                return f\"API Error (403 Forbidden): Authentication failed. Check your API key ('GOOGLE_API_KEY') or ensure it's enabled for the Gemini API. Details: {error_detail}\"\n",
        "            elif status_code == 429:\n",
        "                return f\"API Error (429 Too Many Requests): Rate limit exceeded. Please wait and try again. Details: {error_detail}\"\n",
        "            elif status_code == 500:\n",
        "                return f\"API Error (500 Internal Server Error): Gemini API experienced an internal error. Details: {error_detail}\"\n",
        "            else:\n",
        "                return f\"API HTTP Error ({status_code}): {e.response.reason}. Details: {error_detail}\"\n",
        "        except requests.exceptions.ConnectionError as e:\n",
        "            return f\"Network Error: Could not connect to the Gemini API. Check your internet connection or the API endpoint. Details: {e}\"\n",
        "        except requests.exceptions.Timeout as e:\n",
        "            return f\"Network Error: The request to the Gemini API timed out. Details: {e}\"\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            # Catch all other requests exceptions\n",
        "            return f\"API Request Error: An unexpected issue occurred during the API call. Details: {e}\"\n",
        "        except json.JSONDecodeError:\n",
        "            return \"Error: Could not decode JSON response from API. The API might have returned an invalid or malformed response.\"\n",
        "        except Exception as e:\n",
        "            # Catch any other unexpected Python errors\n",
        "            return f\"An unexpected error occurred during prediction: {e}\"\n",
        "\n",
        "    return \"Error: Failed to predict loan risk after multiple retries. Please try again later.\"\n",
        "\n",
        "\n",
        "# Define Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_loan_risk,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Applicant Age (years)\", minimum=18, value=30),\n",
        "        gr.Number(label=\"Annual Applicant Income ($)\", minimum=0, value=60000),\n",
        "        gr.Number(label=\"Loan Amount ($)\", minimum=1, value=15000),\n",
        "        gr.Number(label=\"Loan Term (months)\", minimum=1, value=36),\n",
        "        gr.Number(label=\"Credit Score (300-850)\", minimum=300, maximum=850, value=720),\n",
        "        gr.Number(label=\"Employment Length (years)\", minimum=0, value=5),\n",
        "        gr.Dropdown(\n",
        "            # Expanded Home Ownership options\n",
        "            [\"Rent\", \"Own\", \"Mortgage\", \"Living with Parents\", \"Other\"],\n",
        "            label=\"Home Ownership\",\n",
        "            value=\"Rent\"\n",
        "        ),\n",
        "        gr.Dropdown(\n",
        "            # Expanded Loan Purpose options\n",
        "            [\"Debt Consolidation\", \"Education\", \"Home Improvement\", \"Venture\",\n",
        "             \"Auto Loan\", \"Medical Expenses\", \"Vacation\", \"Business Expansion\", \"Other\"],\n",
        "            label=\"Loan Purpose\",\n",
        "            value=\"Debt Consolidation\"\n",
        "        ),\n",
        "        gr.Number(label=\"Existing Monthly Debts ($)\", minimum=0, value=500),\n",
        "        gr.Dropdown( # New dropdown for agent selection\n",
        "            [\"General Risk Agent\", \"Financial Stability Agent\", \"Credit History Agent\"],\n",
        "            label=\"Risk Assessment Agent\",\n",
        "            value=\"General Risk Agent\",\n",
        "            info=\"Select an agent to get a specific perspective on loan risk.\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Loan Risk Prediction\"),\n",
        "    title=\"Gen AI Loan Risk Predictor\",\n",
        "    description=\"Enter the loan application details to get a risk assessment using Generative AI (Gemini).\",\n",
        "    css=\"\"\"\n",
        "    body { font-family: 'Inter', sans-serif; }\n",
        "    .gradio-container { border-radius: 12px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }\n",
        "    h1 { color: #1f2937; font-weight: 800; }\n",
        "    p { color: #4b5563; }\n",
        "    button { background-color: #3b82f6 !important; color: white !important; border-radius: 0.375rem !important; }\n",
        "    button:hover { background-color: #2563eb !important; }\n",
        "    input[type=\"number\"], select { border-radius: 0.375rem; border: 1px solid #d1d5db; padding: 0.5rem 0.75rem; }\n",
        "    input[type=\"number\"]:focus, select:focus { outline: none; border-color: #3b82f6; ring: 2px; ring-color: #93c5fd; }\n",
        "    .gr-box { border-radius: 0.5rem; }\n",
        "    .gr-button { border-radius: 0.5rem; }\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(share=True) # Set share=True to get a public link (useful for testing)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from google.colab import userdata  # Only works in Colab\n",
        "\n",
        "# Function to call the Gemini API\n",
        "def predict_loan_risk(\n",
        "    applicant_age: int,\n",
        "    applicant_income: float,\n",
        "    loan_amount: float,\n",
        "    loan_term: int,\n",
        "    credit_score: int,\n",
        "    employment_length: int,\n",
        "    home_ownership: str,\n",
        "    loan_purpose: str,\n",
        "    existing_monthly_debts: float,\n",
        "    risk_agent_type: str\n",
        ") -> str:\n",
        "    api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "    if not api_key:\n",
        "        return \"Error: Gemini API key not found. Please ensure your secret 'GOOGLE_API_KEY' is set up in Colab secrets and notebook access is enabled.\"\n",
        "\n",
        "    base_prompt = f\"\"\"\n",
        "    Analyze the following loan application details and predict the loan risk as \"Low Risk\", \"Medium Risk\", or \"High Risk\".\n",
        "    Provide a detailed justification for your prediction, explaining the key factors that led to the assessment.\n",
        "\n",
        "    Loan Application Details:\n",
        "    - Applicant Age: {applicant_age} years\n",
        "    - Applicant Income: ${applicant_income} per year\n",
        "    - Loan Amount: ${loan_amount}\n",
        "    - Loan Term: {loan_term} months\n",
        "    - Credit Score: {credit_score} (out of 850)\n",
        "    - Employment Length: {employment_length} years\n",
        "    - Home Ownership: {home_ownership}\n",
        "    - Loan Purpose: {loan_purpose}\n",
        "    - Existing Monthly Debts: ${existing_monthly_debts}\n",
        "    \"\"\"\n",
        "\n",
        "    if risk_agent_type == \"Financial Stability Agent\":\n",
        "        agent_specific_instruction = \"Focus your justification primarily on the applicant's income, existing debts, and the loan amount relative to their financial capacity.\"\n",
        "    elif risk_agent_type == \"Credit History Agent\":\n",
        "        agent_specific_instruction = \"Focus your justification primarily on the applicant's credit score and employment stability.\"\n",
        "    else:\n",
        "        agent_specific_instruction = \"Provide a comprehensive justification considering all relevant factors.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    {base_prompt}\n",
        "    {agent_specific_instruction}\n",
        "\n",
        "    Please format your response strictly as follows:\n",
        "    Risk: [Your Prediction]\n",
        "    Justification: [Your Detailed Justification]\n",
        "    \"\"\"\n",
        "\n",
        "    chat_history = [{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}]\n",
        "\n",
        "    payload = {\n",
        "        \"contents\": chat_history,\n",
        "        \"generationConfig\": {\n",
        "            \"responseMimeType\": \"text/plain\",\n",
        "            \"temperature\": 0.7,\n",
        "        },\n",
        "    }\n",
        "\n",
        "    api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key={api_key}\"\n",
        "\n",
        "    retries = 0\n",
        "    max_retries = 5\n",
        "    base_delay = 1\n",
        "\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                api_url,\n",
        "                headers={'Content-Type': 'application/json'},\n",
        "                data=json.dumps(payload)\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "\n",
        "            if result.get(\"candidates\") and len(result[\"candidates\"]) > 0:\n",
        "                if result[\"candidates\"][0].get(\"finishReason\") == \"SAFETY\":\n",
        "                    return \"Prediction blocked due to safety concerns.\"\n",
        "\n",
        "                if result[\"candidates\"][0].get(\"content\") and \\\n",
        "                   result[\"candidates\"][0][\"content\"].get(\"parts\") and \\\n",
        "                   len(result[\"candidates\"][0][\"content\"][\"parts\"]) > 0:\n",
        "\n",
        "                    text = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
        "                    prediction_text = \"N/A\"\n",
        "                    justification_text = \"The model did not provide a specific justification for this prediction.\"\n",
        "\n",
        "                    risk_start_idx = text.find(\"Risk:\")\n",
        "                    justification_start_idx = text.find(\"Justification:\")\n",
        "\n",
        "                    if risk_start_idx != -1:\n",
        "                        if justification_start_idx != -1 and justification_start_idx > risk_start_idx:\n",
        "                            prediction_text = text[risk_start_idx + len(\"Risk:\"):justification_start_idx].strip()\n",
        "                        else:\n",
        "                            prediction_text = text[risk_start_idx + len(\"Risk:\"):].strip()\n",
        "                        if \"Justification:\" in prediction_text:\n",
        "                            prediction_text = prediction_text.split(\"Justification:\")[0].strip()\n",
        "\n",
        "                    if justification_start_idx != -1:\n",
        "                        justification_text = text[justification_start_idx + len(\"Justification:\"):].strip()\n",
        "                        if not justification_text:\n",
        "                            justification_text = \"The model did not provide a specific justification for this prediction.\"\n",
        "\n",
        "                    return (\n",
        "                        f\"**Predicted Risk ({risk_agent_type}):** {prediction_text}\\n\\n\"\n",
        "                        f\"**Justification:** {justification_text}\"\n",
        "                    )\n",
        "                else:\n",
        "                    return \"Error: Gemini API returned an empty content part.\"\n",
        "            else:\n",
        "                return \"Error: Gemini API returned no candidates.\"\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return f\"API Request Error: {e}\"\n",
        "        except json.JSONDecodeError:\n",
        "            return \"Error: Could not decode JSON response.\"\n",
        "        except Exception as e:\n",
        "            return f\"Unexpected error: {e}\"\n",
        "\n",
        "    return \"Error: Failed to predict loan risk after multiple retries.\"\n",
        "\n",
        "# Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_loan_risk,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Applicant Age (years)\", minimum=18, value=30),\n",
        "        gr.Number(label=\"Annual Applicant Income ($)\", minimum=0, value=60000),\n",
        "        gr.Number(label=\"Loan Amount ($)\", minimum=1, value=15000),\n",
        "        gr.Number(label=\"Loan Term (months)\", minimum=1, value=36),\n",
        "        gr.Number(label=\"Credit Score (300-850)\", minimum=300, maximum=850, value=720),\n",
        "        gr.Number(label=\"Employment Length (years)\", minimum=0, value=5),\n",
        "        gr.Dropdown(\n",
        "            [\"Rent\", \"Own\", \"Mortgage\", \"Living with Parents\", \"Other\"],\n",
        "            label=\"Home Ownership\",\n",
        "            value=\"Rent\"\n",
        "        ),\n",
        "        gr.Dropdown(\n",
        "            [\"Debt Consolidation\", \"Education\", \"Home Improvement\", \"Venture\",\n",
        "             \"Auto Loan\", \"Medical Expenses\", \"Vacation\", \"Business Expansion\", \"Other\"],\n",
        "            label=\"Loan Purpose\",\n",
        "            value=\"Debt Consolidation\"\n",
        "        ),\n",
        "        gr.Number(label=\"Existing Monthly Debts ($)\", minimum=0, value=500),\n",
        "        gr.Dropdown(\n",
        "            [\"General Risk Agent\", \"Financial Stability Agent\", \"Credit History Agent\"],\n",
        "            label=\"Risk Assessment Agent\",\n",
        "            value=\"General Risk Agent\",\n",
        "            info=\"Select an agent to get a specific perspective on loan risk.\"\n",
        "        )\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Loan Risk Prediction\"),\n",
        "    title=\"Gen AI Loan Risk Predictor\",\n",
        "    description=\"Enter the loan application details to get a risk assessment using Generative AI (Gemini).\",\n",
        "    flagging_dir=\"flagged_data\",  # 🔥 Enables CSV flag logging\n",
        "    allow_flagging=\"manual\",      # \"manual\" enables user-initiated flagging\n",
        "    css=\"\"\"\n",
        "    body { font-family: 'Inter', sans-serif; }\n",
        "    .gradio-container { border-radius: 12px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }\n",
        "    h1 { color: #1f2937; font-weight: 800; }\n",
        "    p { color: #4b5563; }\n",
        "    button { background-color: #3b82f6 !important; color: white !important; border-radius: 0.375rem !important; }\n",
        "    button:hover { background-color: #2563eb !important; }\n",
        "    input[type=\"number\"], select { border-radius: 0.375rem; border: 1px solid #d1d5db; padding: 0.5rem 0.75rem; }\n",
        "    input[type=\"number\"]:focus, select:focus { outline: none; border-color: #3b82f6; ring: 2px; ring-color: #93c5fd; }\n",
        "    .gr-box { border-radius: 0.5rem; }\n",
        "    .gr-button { border-radius: 0.5rem; }\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Launch app\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "9lUs32scpHLl",
        "outputId": "064324d3-7dc1-4bd7-d311-21b941bb0579"
      },
      "id": "9lUs32scpHLl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:425: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a0b131931951f28f08.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a0b131931951f28f08.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langgraph"
      ],
      "metadata": {
        "id": "R9_GJthgwOKK"
      },
      "id": "R9_GJthgwOKK"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M9cCdGum0Hhw",
        "outputId": "728e921a-7bd8-43d6-f731-c3b1369becca"
      },
      "id": "M9cCdGum0Hhw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.72)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2a3d34d9bedd4342a23ced99f9f0f7c8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "langgraph_multiagent_loan_predictor.py\n",
        "\n",
        "Single-file LangGraph-based nested multi-agent loan risk predictor.\n",
        "\n",
        "- Supervisor is a LangGraph StateGraph that sequentially invokes specialist agents (created with create_react_agent).\n",
        "- Agents are lightweight ReAct agents configured via prompts (the heavy logic is in the prompts; node code is minimal).\n",
        "- Uses Google Gemini via langchain_google_genai.ChatGoogleGenerativeAI (set GEMINI_API_KEY or GOOGLE_API_KEY in env or Colab secrets).\n",
        "\n",
        "Requirements:\n",
        "    pip install gradio requests pydantic langgraph langchain-google-genai\n",
        "\n",
        "Run (Colab): set the secret 'GOOGLE_API_KEY' and run the notebook, then execute this script.\n",
        "\n",
        "Notes about \"chain-of-thought\": prompts instruct the model to *internally* reason but NOT to output chain-of-thought. The agents return a structured response only (risk/score/justification).\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "\n",
        "try:\n",
        "    # LangGraph + helpers\n",
        "    from langgraph.prebuilt import create_react_agent\n",
        "    from langgraph.graph import StateGraph, START, END\n",
        "except Exception:\n",
        "    raise ImportError(\"Please install langgraph: pip install langgraph\")\n",
        "\n",
        "try:\n",
        "    # Google Gemini chat model wrapper for LangChain\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "except Exception:\n",
        "    raise ImportError(\"Please install langchain-google-genai: pip install langchain-google-genai\")\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "import gradio as gr\n",
        "\n",
        "# --- Configuration --------------------------------------------------------\n",
        "API_KEY = \"AIzaSyCXp230h__4BovmnNDxBWwjIfbyZTCvUKA\"\n",
        "if not API_KEY:\n",
        "    # In Colab you can set userdata secrets; as fallback we still try env var.\n",
        "    print(\"Warning: GEMINI/GOOGLE API key not found in environment. Set GOOGLE_API_KEY or GEMINI_API_KEY.\")\n",
        "\n",
        "MODEL_NAME = \"gemini-2.5-pro\"  # you can change to your preferred Gemini model\n",
        "MODEL_TEMPERATURE = 0.0\n",
        "\n",
        "# --- Structured agent response schema ------------------------------------\n",
        "class AgentOutput(BaseModel):\n",
        "    risk: str = Field(..., description=\"One of: Low Risk | Medium Risk | High Risk | N/A\")\n",
        "    score: int = Field(..., ge=0, le=100, description=\"Agent's numeric risk score (0-100)\")\n",
        "    justification: str = Field(..., description=\"Concise structured justification (do NOT output private chain-of-thought)\")\n",
        "\n",
        "# --- State schema for LangGraph ------------------------------------------\n",
        "class LoanState(TypedDict, total=False):\n",
        "    loan: Dict[str, Any]\n",
        "    agents_outputs: List[Dict[str, Any]]\n",
        "    final_assessment: Dict[str, Any]\n",
        "\n",
        "# --- Create the Gemini model wrapper for LangGraph -----------------------\n",
        "# ChatGoogleGenerativeAI requires the API key to be provided via argument or env var.\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=MODEL_NAME,\n",
        "    temperature=MODEL_TEMPERATURE,\n",
        "    google_api_key=API_KEY,\n",
        ")\n",
        "\n",
        "# --- Agents to create (specialist perspectives) ---------------------------\n",
        "AGENT_ORDER = [\n",
        "    \"Intent Validation Agent\",\n",
        "    \"Document Completeness Agent\",\n",
        "    \"Affordability Agent\",\n",
        "    \"Financial Stability Agent\",\n",
        "    \"Credit History Agent\",\n",
        "    \"Employment Stability Agent\",\n",
        "    \"Fraud Detection Agent\",\n",
        "    \"General Risk Agent\",\n",
        "]\n",
        "\n",
        "# Agent-specific focus text (used inside prompts)\n",
        "AGENT_FOCUS = {\n",
        "    \"Intent Validation Agent\": \"Assess whether the stated loan purpose is plausible and coherent given the numeric fields; flag contradictions.\",\n",
        "    \"Document Completeness Agent\": \"Assess if required fields and common verification artifacts appear present. (This agent is a logical stub if no docs provided.)\",\n",
        "    \"Affordability Agent\": \"Compute debt-to-income ratio (DTI) and estimate monthly payment; compare payment against income to judge affordability.\",\n",
        "    \"Financial Stability Agent\": \"Evaluate income stability, savings signals, and existing debts relative to requested loan amount.\",\n",
        "    \"Credit History Agent\": \"Evaluate the credit score and infer likely past behavior; indicate whether credit history alone is decisive.\",\n",
        "    \"Employment Stability Agent\": \"Evaluate employment length and inferred stability; treat 0-1 years as volatile and >3 years as stable, unless contradicted.\",\n",
        "    \"Fraud Detection Agent\": \"Look for implausible numbers or contradictions (e.g., income << monthly debts), and mark suspicious entries.\",\n",
        "    \"General Risk Agent\": \"Synthesize a balanced view across all factors and offer a final perspective.\",\n",
        "}\n",
        "\n",
        "# --- Helper: dynamic prompt builder for agents ---------------------------\n",
        "def make_agent_prompt_callable(agent_name: str):\n",
        "    \"\"\"Return a prompt callable (state, config) -> list[messages].\n",
        "\n",
        "    Important: we instruct the model NOT to output chain-of-thought. Agents should internally reason but only emit\n",
        "    the structured response defined by `AgentOutput`.\n",
        "    \"\"\"\n",
        "    focus = AGENT_FOCUS.get(agent_name, \"Provide a specialist view.\")\n",
        "\n",
        "    def prompt(state: Dict[str, Any], config: Any):\n",
        "        loan = state.get(\"loan\", {})\n",
        "        # Compose the system message with strict output rules\n",
        "        system_msg = (\n",
        "            f\"You are '{agent_name}', an expert loan risk analyst focusing on: {focus}\\n\"\n",
        "            \"INSTRUCTIONS: You MAY reason internally to reach an answer, but DO NOT output any chain-of-thought or step-by-step internal reasoning to the user.\\n\"\n",
        "            \"OUTPUT SCHEMA: You MUST return a JSON object matching this Pydantic schema: {\\\"risk\\\": string, \\\"score\\\": integer 0-100, \\\"justification\\\": string}.\\n\"\n",
        "            \"Return ONLY the structured response (no extra commentary, no internal notes).\\n\"\n",
        "        )\n",
        "\n",
        "        # Build a compact loan summary for the user message\n",
        "        loan_summary_lines = [\n",
        "            f\"Applicant Age: {loan.get('applicant_age')}\",\n",
        "            f\"Annual Income: {loan.get('applicant_income')}\",\n",
        "            f\"Loan Amount: {loan.get('loan_amount')}\",\n",
        "            f\"Loan Term (months): {loan.get('loan_term')}\",\n",
        "            f\"Credit Score: {loan.get('credit_score')}\",\n",
        "            f\"Employment Length (years): {loan.get('employment_length')}\",\n",
        "            f\"Home Ownership: {loan.get('home_ownership')}\",\n",
        "            f\"Loan Purpose: {loan.get('loan_purpose')}\",\n",
        "            f\"Existing Monthly Debts: {loan.get('existing_monthly_debts')}\",\n",
        "        ]\n",
        "        user_msg = (\n",
        "            \"You are given a loan application to assess.\\n\\n\"\n",
        "            \"Loan details:\\n\" + \"\\n\".join([f\"- {l}\" for l in loan_summary_lines]) + \"\\n\\n\"\n",
        "            f\"Focus: {focus}\\n\\n\"\n",
        "            \"Please produce the structured JSON exactly matching the schema. If information is missing or insufficient, return Risk: N/A and explain in justification.\\n\"\n",
        "        )\n",
        "\n",
        "        # Return messages as a list of dicts; LangGraph will convert into message types.\n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": user_msg},\n",
        "        ]\n",
        "\n",
        "    return prompt\n",
        "\n",
        "\n",
        "# --- Create the specialist agents using create_react_agent ----------------\n",
        "print(\"Creating specialist agents (this uses the Gemini model via ChatGoogleGenerativeAI)...\")\n",
        "agents = {}\n",
        "for name in AGENT_ORDER:\n",
        "    prompt_callable = make_agent_prompt_callable(name)\n",
        "    # Create the prebuilt agent. We don't provide tools here; prompts do the heavy lifting.\n",
        "    agent = create_react_agent(\n",
        "        model=llm,\n",
        "        tools=[],\n",
        "        prompt=prompt_callable,\n",
        "        response_format=AgentOutput,  # request structured output\n",
        "        name=name,\n",
        "    )\n",
        "    agents[name] = agent\n",
        "\n",
        "print(f\"Created {len(agents)} agents: {', '.join(agents.keys())}\")\n",
        "\n",
        "# --- Build the supervisor StateGraph (nodes call the agents) -------------\n",
        "\n",
        "workflow = StateGraph(LoanState)\n",
        "\n",
        "# Generic factory to create nodes that call an agent and append to agents_outputs\n",
        "def make_agent_node(agent_name: str, agent_runnable):\n",
        "    def node(state: LoanState):\n",
        "        # Prepare an input for the agent: include the loan dict so the dynamic prompt can read it.\n",
        "        input_state = {\"loan\": state.get(\"loan\", {}), \"messages\": []}\n",
        "        # Invoke the agent runnable; compiled runnable returns a mapping. We attempt to extract structured response.\n",
        "        try:\n",
        "            res = agent_runnable.invoke(input_state)\n",
        "        except Exception as e:\n",
        "            # If agent invocation fails, append a safe N/A entry\n",
        "            output = {\"agent\": agent_name, \"risk\": \"N/A\", \"score\": 50, \"justification\": f\"Agent invocation failed: {e}\"}\n",
        "            outputs = state.get(\"agents_outputs\", []) + [output]\n",
        "            return {\"agents_outputs\": outputs}\n",
        "\n",
        "        # Try several common places where structured output may live\n",
        "        structured = None\n",
        "        if isinstance(res, dict):\n",
        "            structured = res.get(\"structured_response\") or res.get(\"structuredResponse\") or res.get(\"structured_response_text\")\n",
        "        # Fallback: try to parse the last message as JSON\n",
        "        if structured is None:\n",
        "            try:\n",
        "                if isinstance(res, dict) and res.get(\"messages\"):\n",
        "                    last = res[\"messages\"][-1]\n",
        "                    text = last.get(\"content\") if isinstance(last, dict) else str(last)\n",
        "                else:\n",
        "                    text = str(res)\n",
        "                parsed = json.loads(text)\n",
        "                structured = parsed\n",
        "            except Exception:\n",
        "                # As a final fallback, keep the textual content as justification\n",
        "                try:\n",
        "                    text = json.dumps(res)[:1000]\n",
        "                except Exception:\n",
        "                    text = str(res)[:1000]\n",
        "                structured = {\"risk\": \"N/A\", \"score\": 50, \"justification\": text}\n",
        "\n",
        "        # Normalize fields and append the agent name\n",
        "        structured_record = {\n",
        "            \"agent\": agent_name,\n",
        "            \"risk\": structured.get(\"risk\", \"N/A\") if isinstance(structured, dict) else \"N/A\",\n",
        "            \"score\": int(structured.get(\"score\", 50)) if isinstance(structured, dict) and structured.get(\"score\") is not None else 50,\n",
        "            \"justification\": structured.get(\"justification\", str(structured)) if isinstance(structured, dict) else str(structured)\n",
        "        }\n",
        "        outputs = state.get(\"agents_outputs\", []) + [structured_record]\n",
        "        return {\"agents_outputs\": outputs}\n",
        "\n",
        "    return node\n",
        "\n",
        "# Add agent nodes in order and wire edges sequentially\n",
        "prev_node = None\n",
        "for i, name in enumerate(AGENT_ORDER):\n",
        "    node_fn = make_agent_node(name, agents[name])\n",
        "    workflow.add_node(name, node_fn)\n",
        "    if i == 0:\n",
        "        workflow.set_entry_point(name)\n",
        "    else:\n",
        "        workflow.add_edge(prev_node, name)\n",
        "    prev_node = name\n",
        "\n",
        "# Aggregation node: compute final score and label\n",
        "WEIGHTS = {\n",
        "    \"Financial Stability Agent\": 1.2,\n",
        "    \"Credit History Agent\": 1.1,\n",
        "    \"Employment Stability Agent\": 1.0,\n",
        "    \"Affordability Agent\": 1.3,\n",
        "    \"Fraud Detection Agent\": 1.0,\n",
        "    \"Intent Validation Agent\": 0.9,\n",
        "    \"Document Completeness Agent\": 0.6,\n",
        "    \"General Risk Agent\": 1.0,\n",
        "}\n",
        "\n",
        "def aggregate_node(state: LoanState):\n",
        "    outputs = state.get(\"agents_outputs\", [])\n",
        "    if not outputs:\n",
        "        return {\"final_assessment\": {\"final_score\": 50, \"final_label\": \"Medium Risk\", \"explainers\": []}}\n",
        "\n",
        "    total_w = 0.0\n",
        "    weighted = 0.0\n",
        "    for o in outputs:\n",
        "        w = WEIGHTS.get(o.get(\"agent\"), 1.0)\n",
        "        weighted += (o.get(\"score\", 50) or 50) * w\n",
        "        total_w += w\n",
        "    final_score = int(round(weighted / total_w)) if total_w > 0 else 50\n",
        "    if final_score < 35:\n",
        "        final_label = \"Low Risk\"\n",
        "    elif final_score < 65:\n",
        "        final_label = \"Medium Risk\"\n",
        "    else:\n",
        "        final_label = \"High Risk\"\n",
        "\n",
        "    # create short explainers from top-3 contributors\n",
        "    top = sorted(outputs, key=lambda x: x.get(\"score\", 0), reverse=True)[:3]\n",
        "    explainers = [f\"{t['agent']} ({t['score']}): {t['justification'][:160]}\" for t in top]\n",
        "    return {\"final_assessment\": {\"final_score\": final_score, \"final_label\": final_label, \"explainers\": explainers}}\n",
        "\n",
        "workflow.add_node(\"aggregate\", aggregate_node)\n",
        "workflow.add_edge(prev_node, \"aggregate\")\n",
        "workflow.add_edge(\"aggregate\", END)\n",
        "\n",
        "# Compile the graph into a runnable\n",
        "print(\"Compiling LangGraph supervisor workflow...\")\n",
        "compiled = workflow.compile()\n",
        "print(\"Compiled. Runtime is ready.\")\n",
        "\n",
        "# --- Helper to run the compiled graph from an external call ----------------\n",
        "def run_langgraph_supervisor(loan_payload: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Run the compiled LangGraph workflow with the provided loan_payload and return final assessment.\n",
        "\n",
        "    loan_payload should be a dict with keys matching the UI fields (applicant_age, applicant_income, ...)\n",
        "    \"\"\"\n",
        "    initial_state = {\"loan\": loan_payload, \"agents_outputs\": []}\n",
        "    # invoke the compiled graph synchronously\n",
        "    result_state = compiled.invoke(initial_state)\n",
        "    # compiled.invoke typically returns the final state mapping\n",
        "    final = result_state.get(\"final_assessment\") or result_state.get(\"finalAssessment\") or {}\n",
        "    return {\"state\": result_state, \"final_assessment\": final}\n",
        "\n",
        "# --- Gradio UI ------------------------------------------------------------\n",
        "\n",
        "def ui_predict(\n",
        "    applicant_age: float,\n",
        "    applicant_income: float,\n",
        "    loan_amount: float,\n",
        "    loan_term: float,\n",
        "    credit_score: float,\n",
        "    employment_length: float,\n",
        "    home_ownership: str,\n",
        "    loan_purpose: str,\n",
        "    existing_monthly_debts: float,\n",
        "    risk_agent_type: str,\n",
        "):\n",
        "    loan_payload = {\n",
        "        \"applicant_age\": int(round(applicant_age)),\n",
        "        \"applicant_income\": float(applicant_income),\n",
        "        \"loan_amount\": float(loan_amount),\n",
        "        \"loan_term\": int(round(loan_term)),\n",
        "        \"credit_score\": int(round(credit_score)),\n",
        "        \"employment_length\": int(round(employment_length)),\n",
        "        \"home_ownership\": home_ownership,\n",
        "        \"loan_purpose\": loan_purpose,\n",
        "        \"existing_monthly_debts\": float(existing_monthly_debts),\n",
        "    }\n",
        "\n",
        "    # Move the chosen agent to the front of the sequence by configuring runtime config if desired\n",
        "    # (LangGraph dynamic model selection or interrupts could be used; for now we keep preset order.)\n",
        "\n",
        "    run_result = run_langgraph_supervisor(loan_payload)\n",
        "    state = run_result[\"state\"]\n",
        "    final = run_result[\"final_assessment\"]\n",
        "\n",
        "    # Build friendly Markdown output\n",
        "    lines = []\n",
        "    lines.append(f\"## Final Assessment: **{final.get('final_label','N/A')}**\")\n",
        "    lines.append(f\"**Explainable Score (0-100):** {final.get('final_score','N/A')}\")\n",
        "    lines.append(\"\\n### Top contributing reasons:\")\n",
        "    for r in final.get(\"explainers\", []):\n",
        "        lines.append(f\"- {r}\")\n",
        "    lines.append(\"\\n---\\n### Full agent outputs:\")\n",
        "    for a in state.get(\"agents_outputs\", []):\n",
        "        lines.append(f\"**{a.get('agent')}** — Risk: {a.get('risk')}, Score: {a.get('score')}\\n\\nJustification: {a.get('justification')}\")\n",
        "\n",
        "    return \"\\n\\n\".join(lines)\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=ui_predict,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Applicant Age (years)\", minimum=18, value=30),\n",
        "        gr.Number(label=\"Annual Applicant Income ($)\", minimum=0, value=60000),\n",
        "        gr.Number(label=\"Loan Amount ($)\", minimum=1, value=15000),\n",
        "        gr.Number(label=\"Loan Term (months)\", minimum=1, value=36),\n",
        "        gr.Number(label=\"Credit Score (300-850)\", minimum=300, maximum=850, value=720),\n",
        "        gr.Number(label=\"Employment Length (years)\", minimum=0, value=5),\n",
        "        gr.Dropdown([\"Rent\", \"Own\", \"Mortgage\", \"Living with Parents\", \"Other\"], label=\"Home Ownership\", value=\"Rent\"),\n",
        "        gr.Dropdown([\"Debt Consolidation\", \"Education\", \"Home Improvement\", \"Venture\", \"Auto Loan\", \"Medical Expenses\", \"Vacation\", \"Business Expansion\", \"Other\"], label=\"Loan Purpose\", value=\"Debt Consolidation\"),\n",
        "        gr.Number(label=\"Existing Monthly Debts ($)\", minimum=0, value=500),\n",
        "        gr.Dropdown([\"General Risk Agent\", \"Financial Stability Agent\", \"Credit History Agent\"], label=\"Risk Assessment Agent\", value=\"General Risk Agent\"),\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Loan Risk Prediction\"),\n",
        "    title=\"LangGraph — Nested Multi-Agent Loan Risk Predictor\",\n",
        "    description=\"Supervisor-based LangGraph graph that orchestrates specialist agents (Gemini) to produce an explainable risk score.\",\n",
        "    flagging_dir=\"flagged_data\",\n",
        "    allow_flagging=\"manual\",\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Launching Gradio UI — this will call the LangGraph supervisor graph for each request.\")\n",
        "    iface.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "_VgwOtbRxbAw",
        "outputId": "062bc5ec-24cf-4a71-ce51-8d60ba2e06cc"
      },
      "id": "_VgwOtbRxbAw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating specialist agents (this uses the Gemini model via ChatGoogleGenerativeAI)...\n",
            "Created 8 agents: Intent Validation Agent, Document Completeness Agent, Affordability Agent, Financial Stability Agent, Credit History Agent, Employment Stability Agent, Fraud Detection Agent, General Risk Agent\n",
            "Compiling LangGraph supervisor workflow...\n",
            "Compiled. Runtime is ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2855045333.py:146: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Any'. \n",
            "  agent = create_react_agent(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:425: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Gradio UI — this will call the LangGraph supervisor graph for each request.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://479e11955fb1a25acf.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://479e11955fb1a25acf.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## groq langragph"
      ],
      "metadata": {
        "id": "JDijD1Q12W9t"
      },
      "id": "JDijD1Q12W9t"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('groq_api_key')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k9QtMpI42eNW",
        "outputId": "630d38cf-9e27-49d0-ba37-10be3a532ca2"
      },
      "id": "k9QtMpI42eNW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-community  # For additional tool integration                  # Ensures LangGraph models work"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA8hZBl72-ST",
        "outputId": "233381d0-cd21-4332-f4d8-d93d3edde438"
      },
      "id": "WA8hZBl72-ST",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from langgraph.agents import Agent, SupervisorAgent\n",
        "from langgraph.prompts import PromptTemplate\n",
        "from langgraph.memory import InMemoryMemory\n",
        "from langgraph.models import GroqModel\n",
        "\n",
        "# Groq LLaMA 3 70B\n",
        "llama70b = GroqModel(\n",
        "    model=\"llama-3-70b\",\n",
        "    api_key=userdata.get('groq_api_key')\n",
        ")\n",
        "\n",
        "# ----- PROMPT TEMPLATES -----\n",
        "affordability_prompt = PromptTemplate(\n",
        "    \"You are an Affordability Expert. Given: {data}, \"\n",
        "    \"determine if the applicant can afford repayment considering income, expenses, and EMI ratio. \"\n",
        "    \"Return a structured JSON: {{'affordable': True/False, 'reason': '...'}}\"\n",
        ")\n",
        "\n",
        "credit_behavior_prompt = PromptTemplate(\n",
        "    \"You are a Credit Behavior Analyst. Given: {data}, \"\n",
        "    \"analyze past repayment history, defaults, and credit utilization. \"\n",
        "    \"Return: {{'credit_score': 0-850, 'risk_level': 'low/medium/high', 'reason': '...'}}\"\n",
        ")\n",
        "\n",
        "employment_prompt = PromptTemplate(\n",
        "    \"You are an Employment Stability Expert. Given: {data}, \"\n",
        "    \"evaluate job stability and predict income continuity. \"\n",
        "    \"Return structured JSON.\"\n",
        ")\n",
        "\n",
        "intent_prompt = PromptTemplate(\n",
        "    \"You are an Intent Validator. Given: {data}, \"\n",
        "    \"detect any fraudulent or suspicious loan purposes.\"\n",
        ")\n",
        "\n",
        "explain_prompt = PromptTemplate(\n",
        "    \"You are an Explainability Agent. Summarize findings from all sub-agents \"\n",
        "    \"into a human-readable explanation.\"\n",
        ")\n",
        "\n",
        "score_prompt = PromptTemplate(\n",
        "    \"You are a Loan Risk Scorer. Combine all findings into a risk score (0-100) \"\n",
        "    \"and recommendation: 'approve', 'review', or 'reject'.\"\n",
        ")\n",
        "\n",
        "# ----- AGENTS -----\n",
        "affordability_agent = Agent(model=llama70b, prompt=affordability_prompt)\n",
        "credit_behavior_agent = Agent(model=llama70b, prompt=credit_behavior_prompt)\n",
        "employment_agent = Agent(model=llama70b, prompt=employment_prompt)\n",
        "intent_agent = Agent(model=llama70b, prompt=intent_prompt)\n",
        "explainability_agent = Agent(model=llama70b, prompt=explain_prompt)\n",
        "scorecard_agent = Agent(model=llama70b, prompt=score_prompt)\n",
        "\n",
        "# LoanRiskAgent (nested)\n",
        "loan_risk_agent = Agent(\n",
        "    model=llama70b,\n",
        "    prompt=PromptTemplate(\n",
        "        \"As the Loan Risk Master Agent, coordinate sub-agents to analyze: {data}. \"\n",
        "        \"Call AffordabilityAgent, CreditBehaviorAgent, EmploymentAgent, and IntentAgent. \"\n",
        "        \"Collect results, pass them to ExplainabilityAgent and ScorecardAgent, and return the final decision.\"\n",
        "    ),\n",
        "    sub_agents={\n",
        "        \"AffordabilityAgent\": affordability_agent,\n",
        "        \"CreditBehaviorAgent\": credit_behavior_agent,\n",
        "        \"EmploymentAgent\": employment_agent,\n",
        "        \"IntentAgent\": intent_agent,\n",
        "        \"ExplainabilityAgent\": explainability_agent,\n",
        "        \"ScorecardAgent\": scorecard_agent\n",
        "    }\n",
        ")\n",
        "\n",
        "# Supervisor Agent\n",
        "supervisor = SupervisorAgent(\n",
        "    model=llama70b,\n",
        "    agents={\n",
        "        \"LoanRiskAgent\": loan_risk_agent\n",
        "    },\n",
        "    memory=InMemoryMemory()\n",
        ")\n",
        "\n",
        "# LangGraph State Machine\n",
        "graph = StateGraph(supervisor)\n",
        "\n",
        "# Example input\n",
        "applicant_data = {\n",
        "    \"name\": \"Ravi Kumar\",\n",
        "    \"age\": 32,\n",
        "    \"income\": 45000,\n",
        "    \"expenses\": 20000,\n",
        "    \"loan_amount\": 500000,\n",
        "    \"loan_purpose\": \"Business expansion\",\n",
        "    \"employment_status\": \"Salaried\",\n",
        "    \"credit_score\": 720,\n",
        "    \"past_loans\": 2,\n",
        "    \"defaults\": 0\n",
        "}\n",
        "\n",
        "result = graph.run({\"data\": applicant_data})\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "oWl0VPTr2Y9N",
        "outputId": "86739864-9e5b-4cb8-b963-c858f33448cc"
      },
      "id": "oWl0VPTr2Y9N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langgraph.agents'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1406572904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSupervisorAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryMemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGroqModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langgraph.agents'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lnggraph"
      ],
      "metadata": {
        "id": "WnZpBo9PiGaR"
      },
      "id": "WnZpBo9PiGaR"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph langchain-openai tavily-python"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IPlPl0RLkVgM",
        "outputId": "b08c5f90-aeac-4fbc-ab60-2416bd8a57b2"
      },
      "id": "IPlPl0RLkVgM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.7.10-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting langchain-core>=0.1 (from langgraph)\n",
            "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.99.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.16.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Downloading langgraph-0.6.4-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.29-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tavily_python-0.7.10-py3-none-any.whl (15 kB)\n",
            "Downloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, tavily-python, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.72\n",
            "    Uninstalling langchain-core-0.3.72:\n",
            "      Successfully uninstalled langchain-core-0.3.72\n",
            "Successfully installed langchain-core-0.3.74 langchain-openai-0.3.29 langgraph-0.6.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 ormsgpack-1.10.0 tavily-python-0.7.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain_core"
                ]
              },
              "id": "46dcf7fe22ef48f988cfa5b9c77bf916"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "from google.colab import userdata  # Import userdata to access Colab secrets\n",
        "from typing import TypedDict, Dict, Any, Union\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# --- Configuration ---\n",
        "GEMINI_MODEL = \"gemini-1.5-flash-latest\" # Use a valid and current model name\n",
        "\n",
        "# Use a TypedDict to represent the state of our graph\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of the Langgraph workflow.\n",
        "    \"\"\"\n",
        "    loan_application: Dict[str, Union[str, int, float]]\n",
        "    decision: str\n",
        "    prediction: str\n",
        "    justification: str\n",
        "    error: str\n",
        "\n",
        "# Define a function to call the Gemini API\n",
        "def call_gemini_api(prompt: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    A helper function to call the Gemini API with exponential backoff and JSON mode.\n",
        "    \"\"\"\n",
        "    api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "    if not api_key:\n",
        "        print(\"Error: Gemini API key not found in Colab secrets.\")\n",
        "        return {\"error\": \"Error: Gemini API key not found.\"}\n",
        "\n",
        "    api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={api_key}\"\n",
        "    payload = {\n",
        "        \"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}],\n",
        "        \"generationConfig\": {\n",
        "            # Request JSON output for more reliable parsing\n",
        "            \"responseMimeType\": \"application/json\",\n",
        "            \"temperature\": 0.7,\n",
        "        },\n",
        "    }\n",
        "\n",
        "    retries = 0\n",
        "    max_retries = 5\n",
        "    base_delay = 1\n",
        "\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                api_url,\n",
        "                headers={'Content-Type': 'application/json'},\n",
        "                data=json.dumps(payload)\n",
        "            )\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "\n",
        "            if result.get(\"candidates\") and len(result[\"candidates\"]) > 0:\n",
        "                candidate = result[\"candidates\"][0]\n",
        "                if candidate.get(\"finishReason\") == \"SAFETY\":\n",
        "                    return {\"error\": \"Prediction blocked due to safety concerns.\"}\n",
        "\n",
        "                content = candidate.get(\"content\")\n",
        "                if content and content.get(\"parts\") and len(content[\"parts\"]) > 0:\n",
        "                    text = content[\"parts\"][0].get(\"text\")\n",
        "                    if text:\n",
        "                        # Clean up potential markdown formatting from the response\n",
        "                        cleaned_text = text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "                        return {\"text\": cleaned_text}\n",
        "                    else:\n",
        "                        return {\"error\": \"API response part has no text.\"}\n",
        "            return {\"error\": \"Gemini API returned no candidates.\"}\n",
        "\n",
        "        except requests.exceptions.HTTPError as e:\n",
        "            if e.response.status_code == 429:\n",
        "                delay = base_delay * (2 ** retries)\n",
        "                print(f\"Rate limit hit. Retrying in {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "                retries += 1\n",
        "                continue\n",
        "            error_message = f\"API HTTP Error ({e.response.status_code}): {e.response.reason}\"\n",
        "            print(error_message)\n",
        "            return {\"error\": error_message}\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            error_message = f\"API Request Error: {e}\"\n",
        "            print(error_message)\n",
        "            return {\"error\": error_message}\n",
        "        except json.JSONDecodeError:\n",
        "            error_message = f\"Could not decode JSON response from API. Response text: {response.text}\"\n",
        "            print(error_message)\n",
        "            return {\"error\": error_message}\n",
        "        except KeyError as e:\n",
        "            error_message = f\"KeyError: Missing expected key in API response: {e}\"\n",
        "            print(f\"Full API response at time of error: {json.dumps(result, indent=2)}\")\n",
        "            return {\"error\": error_message}\n",
        "\n",
        "    return {\"error\": \"Failed to get a valid response from the API after multiple retries.\"}\n",
        "\n",
        "# --- Langgraph Agent Definitions ---\n",
        "\n",
        "# Router Agent\n",
        "def router_agent(state: AgentState):\n",
        "    \"\"\"\n",
        "    This agent automatically determines which specialized agent to use based on application data.\n",
        "    \"\"\"\n",
        "    print(\"--- ROUTER AGENT: Deciding which specialized agent to use ---\")\n",
        "    loan_application = state['loan_application']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following loan application and determine the primary risk factor.\n",
        "    Based on this, which agent is best suited: FinancialStabilityAgent (income, debts, loan amount) or CreditHistoryAgent (credit score, employment history)?\n",
        "\n",
        "    Loan Application: {json.dumps(loan_application, indent=2)}\n",
        "\n",
        "    Respond with ONLY a valid JSON object in the format:\n",
        "    {{\"decision\": \"agent_name\"}}\n",
        "\n",
        "    Where 'agent_name' is either 'FinancialStabilityAgent' or 'CreditHistoryAgent'.\n",
        "    \"\"\"\n",
        "\n",
        "    response = call_gemini_api(prompt)\n",
        "    if 'error' in response:\n",
        "        return {'error': response['error']}\n",
        "\n",
        "    decision_key = \"financial_stability\" # Default value\n",
        "    try:\n",
        "        data = json.loads(response['text'])\n",
        "        decision = data.get('decision', 'FinancialStabilityAgent')\n",
        "\n",
        "        if \"CreditHistoryAgent\" in decision:\n",
        "            decision_key = \"credit_history\"\n",
        "        else:\n",
        "            decision_key = \"financial_stability\"\n",
        "\n",
        "    except (json.JSONDecodeError, KeyError):\n",
        "        print(f\"Failed to parse router's JSON response. Using default. Raw text: {response['text']}\")\n",
        "        # Keep the default decision_key\n",
        "\n",
        "    print(f\"--- ROUTER AGENT: Selected '{decision_key}' agent ---\")\n",
        "    return {\"decision\": decision_key}\n",
        "\n",
        "# Financial Stability Agent\n",
        "def financial_stability_agent(state: AgentState):\n",
        "    \"\"\"\n",
        "    Analyzes the loan application focusing on financial stability using JSON I/O.\n",
        "    \"\"\"\n",
        "    print(\"--- FINANCIAL STABILITY AGENT: Analyzing... ---\")\n",
        "    loan_application = state['loan_application']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a Financial Stability Agent. Analyze the following loan application and predict the loan risk as \"Low Risk\", \"Medium Risk\", or \"High Risk\".\n",
        "    Focus your justification primarily on income, existing debts, and loan amount relative to financial capacity.\n",
        "\n",
        "    Loan Application: {json.dumps(loan_application, indent=2)}\n",
        "\n",
        "    Please format your response strictly as a valid JSON object with \"risk\" and \"justification\" keys.\n",
        "    Example: {{\"risk\": \"Medium Risk\", \"justification\": \"The loan-to-income ratio is high, but the applicant has stable income.\"}}\n",
        "    \"\"\"\n",
        "\n",
        "    response = call_gemini_api(prompt)\n",
        "    if 'error' in response:\n",
        "        return {'error': response['error']}\n",
        "\n",
        "    try:\n",
        "        data = json.loads(response['text'])\n",
        "        prediction = data.get('risk', 'N/A')\n",
        "        justification = data.get('justification', 'No justification provided.')\n",
        "    except json.JSONDecodeError:\n",
        "        prediction = \"Error\"\n",
        "        justification = f\"Failed to parse agent's JSON response. Raw output: {response.get('text', 'N/A')}\"\n",
        "\n",
        "    print(\"--- FINANCIAL STABILITY AGENT: Analysis complete ---\")\n",
        "    return {\"prediction\": prediction, \"justification\": justification}\n",
        "\n",
        "# Credit History Agent\n",
        "def credit_history_agent(state: AgentState):\n",
        "    \"\"\"\n",
        "    Analyzes the loan application focusing on credit history using JSON I/O.\n",
        "    \"\"\"\n",
        "    print(\"--- CREDIT HISTORY AGENT: Analyzing... ---\")\n",
        "    loan_application = state['loan_application']\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a Credit History Agent. Analyze the following loan application and predict the loan risk as \"Low Risk\", \"Medium Risk\", or \"High Risk\".\n",
        "    Focus your justification primarily on the applicant's credit score and employment stability.\n",
        "\n",
        "    Loan Application: {json.dumps(loan_application, indent=2)}\n",
        "\n",
        "    Please format your response strictly as a valid JSON object with \"risk\" and \"justification\" keys.\n",
        "    Example: {{\"risk\": \"Low Risk\", \"justification\": \"The applicant has an excellent credit score and a long, stable employment history.\"}}\n",
        "    \"\"\"\n",
        "\n",
        "    response = call_gemini_api(prompt)\n",
        "    if 'error' in response:\n",
        "        return {'error': response['error']}\n",
        "\n",
        "    try:\n",
        "        data = json.loads(response['text'])\n",
        "        prediction = data.get('risk', 'N/A')\n",
        "        justification = data.get('justification', 'No justification provided.')\n",
        "    except json.JSONDecodeError:\n",
        "        prediction = \"Error\"\n",
        "        justification = f\"Failed to parse agent's JSON response. Raw output: {response.get('text', 'N/A')}\"\n",
        "\n",
        "    print(\"--- CREDIT HISTORY AGENT: Analysis complete ---\")\n",
        "    return {\"prediction\": prediction, \"justification\": justification}\n",
        "\n",
        "# Build the Langgraph graph\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow.add_node(\"router\", router_agent)\n",
        "workflow.add_node(\"financial_stability\", financial_stability_agent)\n",
        "workflow.add_node(\"credit_history\", credit_history_agent)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"router\")\n",
        "\n",
        "# Define the conditional logic to route to the correct agent\n",
        "def route_to_agent(state):\n",
        "    return state.get(\"decision\", \"financial_stability\") # Default route\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"router\",\n",
        "    route_to_agent,\n",
        "    {\n",
        "        \"financial_stability\": \"financial_stability\",\n",
        "        \"credit_history\": \"credit_history\",\n",
        "    }\n",
        ")\n",
        "\n",
        "# After a specialist agent has run, the graph ends.\n",
        "workflow.add_edge(\"financial_stability\", END)\n",
        "workflow.add_edge(\"credit_history\", END)\n",
        "\n",
        "app = workflow.compile()\n",
        "\n",
        "# Main function to handle the Gradio request\n",
        "def predict_loan_risk_with_langgraph(\n",
        "    applicant_age: int,\n",
        "    applicant_income: float,\n",
        "    loan_amount: float,\n",
        "    loan_term: int,\n",
        "    credit_score: int,\n",
        "    employment_length: int,\n",
        "    home_ownership: str,\n",
        "    loan_purpose: str,\n",
        "    existing_monthly_debts: float,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Predicts loan risk using a Langgraph-powered multi-agent system.\n",
        "    \"\"\"\n",
        "    initial_state = {\n",
        "        'loan_application': {\n",
        "            \"applicant_age\": applicant_age,\n",
        "            \"applicant_income\": applicant_income,\n",
        "            \"loan_amount\": loan_amount,\n",
        "            \"loan_term\": loan_term,\n",
        "            \"credit_score\": credit_score,\n",
        "            \"employment_length\": employment_length,\n",
        "            \"home_ownership\": home_ownership,\n",
        "            \"loan_purpose\": loan_purpose,\n",
        "            \"existing_monthly_debts\": existing_monthly_debts,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        final_state = app.invoke(initial_state)\n",
        "\n",
        "        print(f\"Final State: {json.dumps(final_state, indent=2)}\")\n",
        "\n",
        "        if final_state.get('error'):\n",
        "            return f\"**Error:** {final_state['error']}\"\n",
        "\n",
        "        prediction = final_state.get('prediction', 'N/A')\n",
        "        justification = final_state.get('justification', 'No justification provided.')\n",
        "\n",
        "        agent_decision = final_state.get('decision')\n",
        "        if agent_decision == \"credit_history\":\n",
        "            agent_type = \"Credit History Agent\"\n",
        "        else: # Default to financial stability\n",
        "             agent_type = \"Financial Stability Agent\"\n",
        "\n",
        "        return (\n",
        "            f\"**Predicted Risk (via {agent_type}):** {prediction}\\n\\n\"\n",
        "            f\"**Justification:** {justification}\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return f\"An unexpected error occurred during prediction: {e}\"\n",
        "\n",
        "# Define the Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_loan_risk_with_langgraph,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Applicant Age (years)\", minimum=18, value=30),\n",
        "        gr.Number(label=\"Annual Applicant Income ($)\", minimum=0, value=60000),\n",
        "        gr.Number(label=\"Loan Amount ($)\", minimum=1, value=15000),\n",
        "        gr.Number(label=\"Loan Term (months)\", minimum=1, value=36),\n",
        "        gr.Number(label=\"Credit Score (300-850)\", minimum=300, maximum=850, value=720),\n",
        "        gr.Number(label=\"Employment Length (years)\", minimum=0, value=5),\n",
        "        gr.Dropdown(\n",
        "            [\"Rent\", \"Own\", \"Mortgage\", \"Living with Parents\", \"Other\"],\n",
        "            label=\"Home Ownership\",\n",
        "            value=\"Rent\"\n",
        "        ),\n",
        "        gr.Dropdown(\n",
        "            [\"Debt Consolidation\", \"Education\", \"Home Improvement\", \"Venture\",\n",
        "             \"Auto Loan\", \"Medical Expenses\", \"Vacation\", \"Business Expansion\", \"Other\"],\n",
        "            label=\"Loan Purpose\",\n",
        "            value=\"Debt Consolidation\"\n",
        "        ),\n",
        "        gr.Number(label=\"Existing Monthly Debts ($)\", minimum=0, value=500),\n",
        "    ],\n",
        "    outputs=gr.Markdown(label=\"Loan Risk Prediction\"),\n",
        "    title=\"Gen AI Loan Risk Predictor (Automated Agents)\",\n",
        "    description=\"Enter the loan application details. A multi-agent system will automatically select the best agent to provide a risk assessment using Gemini.\",\n",
        "    css=\"\"\"\n",
        "    body { font-family: 'Inter', sans-serif; }\n",
        "    .gradio-container { border-radius: 12px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); }\n",
        "    h1 { color: #1f2937; font-weight: 800; }\n",
        "    p { color: #4b5563; }\n",
        "    button { background-color: #3b82f6 !important; color: white !important; border-radius: 0.375rem !important; }\n",
        "    button:hover { background-color: #2563eb !important; }\n",
        "    input[type=\"number\"], select { border-radius: 0.375rem; border: 1px solid #d1d5db; padding: 0.5rem 0.75rem; }\n",
        "    input[type=\"number\"]:focus, select:focus { outline: none; border-color: #3b82f6; ring: 2px; ring-color: #93c5fd; }\n",
        "    .gr-box { border-radius: 0.5rem; }\n",
        "    .gr-button { border-radius: 0.5rem; }\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "if __name__ == \"__main__\":\n",
        "    # Remember to set your GOOGLE_API_KEY in the Colab secrets manager\n",
        "    # from google.colab import userdata\n",
        "    # userdata.get('GOOGLE_API_KEY')\n",
        "    iface.launch(share=True, debug=True) # Set share=True for a public link"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mOlYlKv-iIOV",
        "outputId": "71014a33-0e8b-45af-f48a-540092ab0bcf"
      },
      "id": "mOlYlKv-iIOV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a458d6f35a5fe4154d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a458d6f35a5fe4154d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ROUTER AGENT: Deciding which specialized agent to use ---\n",
            "--- ROUTER AGENT: Selected 'financial_stability' agent ---\n",
            "--- FINANCIAL STABILITY AGENT: Analyzing... ---\n",
            "--- FINANCIAL STABILITY AGENT: Analysis complete ---\n",
            "Final State: {\n",
            "  \"loan_application\": {\n",
            "    \"applicant_age\": 30,\n",
            "    \"applicant_income\": 60000,\n",
            "    \"loan_amount\": 15000,\n",
            "    \"loan_term\": 36,\n",
            "    \"credit_score\": 720,\n",
            "    \"employment_length\": 5,\n",
            "    \"home_ownership\": \"Rent\",\n",
            "    \"loan_purpose\": \"Debt Consolidation\",\n",
            "    \"existing_monthly_debts\": 500\n",
            "  },\n",
            "  \"decision\": \"financial_stability\",\n",
            "  \"prediction\": \"Low Risk\",\n",
            "  \"justification\": \"The applicant has a stable income of $60,000, and the loan amount of $15,000 is relatively small compared to their income.  Their existing monthly debts are low at $500. The loan-to-income ratio is also low.  All of these factors point to a low risk of default.\"\n",
            "}\n",
            "--- ROUTER AGENT: Deciding which specialized agent to use ---\n",
            "--- ROUTER AGENT: Selected 'financial_stability' agent ---\n",
            "--- FINANCIAL STABILITY AGENT: Analyzing... ---\n",
            "--- FINANCIAL STABILITY AGENT: Analysis complete ---\n",
            "Final State: {\n",
            "  \"loan_application\": {\n",
            "    \"applicant_age\": 30,\n",
            "    \"applicant_income\": 60000,\n",
            "    \"loan_amount\": 150000,\n",
            "    \"loan_term\": 36,\n",
            "    \"credit_score\": 560,\n",
            "    \"employment_length\": 5,\n",
            "    \"home_ownership\": \"Rent\",\n",
            "    \"loan_purpose\": \"Debt Consolidation\",\n",
            "    \"existing_monthly_debts\": 500\n",
            "  },\n",
            "  \"decision\": \"financial_stability\",\n",
            "  \"prediction\": \"High Risk\",\n",
            "  \"justification\": \"The applicant has a low credit score (560), a high loan amount (150000) relative to their annual income (60000), and a loan-to-income ratio exceeding 2.5. While their existing monthly debts are relatively low (500), the substantial loan amount poses a significant financial burden, increasing the risk of default.\"\n",
            "}\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://90bfa7e0c5a008bd4a.gradio.live\n",
            "Killing tunnel 127.0.0.1:7861 <> https://a458d6f35a5fe4154d.gradio.live\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}